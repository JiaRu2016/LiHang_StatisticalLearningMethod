{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification & Notation\n",
    "\n",
    "state set \n",
    "$$ S = \\{ s_1, s_2, \\dots, s_N \\}, \\quad s_i, s_j$$\n",
    "\n",
    "obseration set \n",
    "$$ O = \\{ o_1, o_2, \\dots, o_M \\}, \\quad o_k $$\n",
    "\n",
    "model parameter\n",
    "$$ \\lambda  =  (\\pi, A, B) $$   \n",
    "where\n",
    "$$ A_{ij} = P(s^{(t)} = s_j | s^{(t-1)} = s_i)$$   \n",
    "$$ B_{j}(k) = P(o = o_k | s = s_j)$$   \n",
    "$$ \\pi_i = P(s^{(1)} = s_i)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch and its \"greeks\"\n",
    "\n",
    "#### 定义\n",
    "$\\alpha$ is complete data prob, while $\\beta$ is cond prob\n",
    "\n",
    "$$ \\alpha_t(i) \\overset{def}{=} P(o_1, \\dots, o_t, s_t = s_i | \\lambda) $$   \n",
    "$$ \\beta_t(i) \\overset{def}{=} P(o_{t+1}, \\dots, o_T, | s_t = s_i, \\lambda) $$\n",
    "\n",
    "conditional prob (conditional on total observation seq $O$):\n",
    "\n",
    "$$ \\gamma_t(i) \\overset{def}{=} P(s_t = s_i | O, \\lambda) $$   \n",
    "$$ \\xi_t(i, j) \\overset{def}{=} P(s_t = s_i, s_{t+1} = s_j | O, \\lambda) $$   \n",
    "\n",
    "#### 递推公式\n",
    "\n",
    "forward-backward formula of $\\alpha, \\beta$\n",
    "\n",
    "$$ \\alpha_{t+1}(i) = \\big( \\sum_{j=1}^N \\alpha_t(j) A_{ji} \\big) B_i(o_{t+1}) $$\n",
    "$$ \\alpha_1(i) = \\pi_i B_i(o_1) $$\n",
    "\n",
    "$$ \\beta_t(i) = \\sum_{j=1}^N \\beta_{t+1}(j) A_{ij} B_i(o_t) $$\n",
    "$$ \\beta_T(i) = 1 $$\n",
    "\n",
    "#### gamma, xi 定义 && 公式\n",
    "\n",
    "$$\\gamma_t(i) \\overset{def}{=} P(s_t = i | O, \\lambda) $$\n",
    "$$\\xi_t(i, j) \\overset{def}{=} P(s_t = i, s_{t+1} = j | O, \\lambda) $$\n",
    "\n",
    "$\\gamma$ and $\\xi$ formula (based on alpha and beta)\n",
    "\n",
    "$$ \\gamma_t(i) = \\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_{s=1}^N \\alpha_t(s) \\beta_t(s)} $$\n",
    "\n",
    "$$ \\xi_t(i, j) = \\frac{\\alpha_t(i)\\ A_{ij}\\ \\beta_{t+1}(j) \\ B_j(o_{t+1})}{\\sum_{s=1}^N \\sum_{q=1}^N ...} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./HMM_greeks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi and its greeks\n",
    "\n",
    "定义两个变量： **$t$时刻、状态为$i$、观察为$o$的所有路径中，概率最大的那个路径**\n",
    "\n",
    "- 路径的概率为 $\\delta_t(i)$\n",
    "- 路径 $t-1$ 时刻节点值为 $\\psi_t(i)$\n",
    "\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\delta_t(i)      =&  \\max_{s_1, s_2, ..., s_{t-1}} P(s_1, ..., s_{t-1}, s_t = i, o_1, ..., o_t | \\lambda) \\\\ \n",
    "\\delta_{t+1}(i)  =&  \\max_{j}[\\delta_t(j) A_{ji}] B_i(o_{t+1}) \\\\\n",
    "\\psi_t(i)        =&  \\argmax_j  \\delta_{t-1}(j)A_{ji}    \n",
    "\\end{align}$$\n",
    "\n",
    "Viterbi算法：\n",
    "\n",
    "1. 从前向后计算每个节点（所有可能状态）的 $\\delta_t(i)$, $\\psi_t(i)$\n",
    "2. 往前回溯，找出整个路径\n",
    "\n",
    "具体的：\n",
    "\n",
    "1. 初始化\n",
    "$$ \\delta_1(i) = \\pi(i) B_i(o_1) $$\n",
    "\n",
    "2. for t = 2 ~ T, 根据递推公式计算 $\\delta_t(i)$, $\\psi_t(i)$\n",
    "\n",
    "3. T时刻的 $\\delta$ 即为最大概率，对应的 $\\argmax_j$ 即为最后一个节点的状态\n",
    "$$ P^* = \\max_j \\delta_T(j) $$\n",
    "$$ s_T^* = \\argmax_j \\delta_T(j) $$\n",
    "\n",
    "4. 往前回溯\n",
    "$$ s_t^* = \\psi_{t+1}(s_{t+1}^*) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](HMM_greeks_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generating Process\n",
    "\n",
    "class HMM(object):\n",
    "    \"\"\"Hidden Markov Model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pi, A, B, T=10, observation_set=None, state_set=None):\n",
    "        \n",
    "        self.N = pi.shape[0]\n",
    "        self.M = B.shape[1]\n",
    "        assert A.shape == (self.N, self.N)\n",
    "        assert B.shape == (self.N, self.M)\n",
    "        \n",
    "        self.pi = pi\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        assert T > 0 and type(T) is int\n",
    "        self.T = T\n",
    "        \n",
    "        if observation_set is None:\n",
    "            observation_set = list('Obs' + str(i) for i in range(self.M))\n",
    "        if state_set is None:\n",
    "            state_set = list('State' + str(i) for i in range(self.N))    \n",
    "        \n",
    "        assert len(observation_set) == self.M\n",
    "        assert len(state_set) == self.N\n",
    "        \n",
    "        self.observation_set = observation_set\n",
    "        self.statet_set = state_set\n",
    "\n",
    "    def generate_one_sample(self):\n",
    "        pi, A, B, T, N, M = self.pi, self.A, self.B, self.T, self.N, self.M\n",
    "        \n",
    "        s = np.zeros(T).astype(int)\n",
    "        o = np.zeros(T).astype(int)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        s[0] = np.random.choice(N, p=pi)\n",
    "        o[0] = np.random.choice(M, p=B[s[0],:])\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            s[t] = np.random.choice(N, p=A[s[t-1], :])\n",
    "            o[t] = np.random.choice(M, p=B[s[t], :])\n",
    "            \n",
    "        return s, o\n",
    "    \n",
    "    def viterbi(self, o, lambda_ = None):\n",
    "        \"\"\"viterbi算法\n",
    "        \n",
    "        已知 O, (pi, A, B)，估计 I\n",
    "        1. 初始化 delta_0(i) = pi(i)B_i(o1)\n",
    "        2. 递推算出 delta_t(i), psi_t(i)\n",
    "        3. 回溯 psi_t\n",
    "        \"\"\"\n",
    "        if lambda_ is None:\n",
    "            pi, A, B = self.pi, self.A, self.B\n",
    "            N, M = self.N, self.M\n",
    "            T = len(o)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        lattice_delta = np.full((N, T), np.nan)\n",
    "        lattice_psi = np.full((N, T), np.nan)\n",
    "        \n",
    "        lattice_delta[:, 0] = pi * B[:, o[0]]\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            for i in range(N):\n",
    "                j, prob = self._which_max(lattice_delta[:, t-1] * A[:, i] * B[i, o[t]])\n",
    "                lattice_delta[i, t] = prob\n",
    "                lattice_psi[i, t] = j\n",
    "                \n",
    "        self.lattice_delta = lattice_delta\n",
    "        self.lattice_psi = lattice_psi\n",
    "        \n",
    "        j, prob = self._which_max(lattice_delta[:, T-1])\n",
    "        \n",
    "        s = np.zeros(T).astype(int)\n",
    "        s[T-1] = j\n",
    "        for t in range(T-1, 0, -1):\n",
    "            s[t-1] = lattice_psi[s[t], t]\n",
    "\n",
    "        return s\n",
    "    \n",
    "    def _which_max(self, iterable):\n",
    "        idx, value = 0, -np.inf\n",
    "        for i, it in enumerate(iterable):\n",
    "            if it > value:\n",
    "                value = it\n",
    "                idx = i\n",
    "        return idx, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_set = ['红', '白']\n",
    "state_set = ['box1', 'box2', 'box3', 'box4']\n",
    "\n",
    "pi = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "A = np.array([[0, 1, 0, 0],\n",
    "              [.4, 0, .6, 0],\n",
    "              [0, .4, 0, .6],\n",
    "              [0, 0, .5, .5],\n",
    "             ])\n",
    "B = np.array([[.5, .5],\n",
    "              [.3, .7],\n",
    "              [.6, .4],\n",
    "              [.8, .2],\n",
    "             ])\n",
    "\n",
    "# model ======================================================\n",
    "\n",
    "m = HMM(pi, A, B, 10, obs_set, state_set)\n",
    "s, o = m.generate_one_sample()\n",
    "s_hat = m.viterbi(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [nan,  0.,  2.,  0.,  0.,  2.,  2.,  2.,  2.,  0.],\n",
       "       [nan,  3.,  3.,  1.,  3.,  3.,  3.,  3.,  1.,  3.],\n",
       "       [nan,  3.,  3.,  2.,  3.,  3.,  3.,  3.,  2.,  3.]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.lattice_delta\n",
    "m.lattice_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 3, 3, 2, 3, 3])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 2, 3, 2, 1, 2, 3])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hmm.MultinomialHMM  # Hidden Markov Model with multinomial (discrete) emissions\n",
    "hmm.GaussianHMM     # Hidden Markov Model with Gaussian emissions.\n",
    "hmm.GMMHMM          # Hidden Markov Model with Gaussian mixture emissions.\n",
    "# dir(hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 3, 3, 2, 3, 3])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=4)\n",
    "model.startprob_ = pi\n",
    "model.transmat_ = A\n",
    "model.emissionprob_ = B\n",
    "prob, state_seq = model.decode(o.reshape(-1,1))\n",
    "\n",
    "state_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_seq - s_hat   # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
