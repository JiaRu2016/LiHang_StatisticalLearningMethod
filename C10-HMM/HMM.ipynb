{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification & Notation\n",
    "\n",
    "state set \n",
    "$$ S = \\{ s_1, s_2, \\dots, s_N \\}, \\quad s_i, s_j$$\n",
    "\n",
    "obseration set \n",
    "$$ O = \\{ o_1, o_2, \\dots, o_M \\}, \\quad o_k $$\n",
    "\n",
    "model parameter\n",
    "$$ \\lambda  =  (\\pi, A, B) $$   \n",
    "where\n",
    "$$ A_{ij} = P(s^{(t)} = s_j | s^{(t-1)} = s_i)$$   \n",
    "$$ B_{j}(k) = P(o = o_k | s = s_j)$$   \n",
    "$$ \\pi_i = P(s^{(1)} = s_i)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch and its \"greeks\"\n",
    "\n",
    "#### 定义\n",
    "$\\alpha$ is complete data prob, while $\\beta$ is cond prob\n",
    "\n",
    "$$ \\alpha_t(i) \\overset{def}{=} P(o_1, \\dots, o_t, s_t = s_i | \\lambda) $$   \n",
    "$$ \\beta_t(i) \\overset{def}{=} P(o_{t+1}, \\dots, o_T, | s_t = s_i, \\lambda) $$\n",
    "\n",
    "conditional prob (conditional on total observation seq $O$):\n",
    "\n",
    "$$ \\gamma_t(i) \\overset{def}{=} P(s_t = s_i | O, \\lambda) $$   \n",
    "$$ \\xi_t(i, j) \\overset{def}{=} P(s_t = s_i, s_{t+1} = s_j | O, \\lambda) $$   \n",
    "\n",
    "#### 递推公式\n",
    "\n",
    "forward-backward formula of $\\alpha, \\beta$\n",
    "\n",
    "$$ \\alpha_{t+1}(i) = \\big( \\sum_{j=1}^N \\alpha_t(j) A_{ji} \\big) B_i(o_{t+1}) $$\n",
    "$$ \\alpha_1(i) = \\pi_i B_i(o_1) $$\n",
    "\n",
    "$$ \\beta_t(i) = \\sum_{j=1}^N \\beta_{t+1}(j) A_{ij} B_i(o_t) $$\n",
    "$$ \\beta_T(i) = 1 $$\n",
    "\n",
    "#### gamma, xi 定义 && 公式\n",
    "\n",
    "$$\\gamma_t(i) \\overset{def}{=} P(s_t = i | O, \\lambda) $$\n",
    "$$\\xi_t(i, j) \\overset{def}{=} P(s_t = i, s_{t+1} = j | O, \\lambda) $$\n",
    "\n",
    "$\\gamma$ and $\\xi$ formula (based on alpha and beta)\n",
    "\n",
    "$$ \\gamma_t(i) = \\frac{\\alpha_t(i) \\beta_t(i)}{\\sum_{s=1}^N \\alpha_t(s) \\beta_t(s)} $$\n",
    "\n",
    "$$ \\xi_t(i, j) = \\frac{\\alpha_t(i)\\ A_{ij}\\ \\beta_{t+1}(j) \\ B_j(o_{t+1})}{\\sum_{s=1}^N \\sum_{q=1}^N ...} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./HMM_greeks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi and its greeks\n",
    "\n",
    "定义两个变量： **$t$时刻、状态为$i$、观察为$o$的所有路径中，概率最大的那个路径**\n",
    "\n",
    "- 路径的概率为 $\\delta_t(i)$\n",
    "- 路径 $t-1$ 时刻节点值为 $\\psi_t(i)$\n",
    "\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\delta_t(i)      =&  \\max_{s_1, s_2, ..., s_{t-1}} P(s_1, ..., s_{t-1}, s_t = i, o_1, ..., o_t | \\lambda) \\\\ \n",
    "\\delta_{t+1}(i)  =&  \\max_{j}[\\delta_t(j) A_{ji}] B_i(o_{t+1}) \\\\\n",
    "\\psi_t(i)        =&  \\argmax_j  \\delta_{t-1}(j)A_{ji}    \n",
    "\\end{align}$$\n",
    "\n",
    "Viterbi算法：\n",
    "\n",
    "1. 从前向后计算每个节点（所有可能状态）的 $\\delta_t(i)$, $\\psi_t(i)$\n",
    "2. 往前回溯，找出整个路径\n",
    "\n",
    "具体的：\n",
    "\n",
    "1. 初始化\n",
    "$$ \\delta_1(i) = \\pi(i) B_i(o_1) $$\n",
    "\n",
    "2. for t = 2 ~ T, 根据递推公式计算 $\\delta_t(i)$, $\\psi_t(i)$\n",
    "\n",
    "3. T时刻的 $\\delta$ 即为最大概率，对应的 $\\argmax_j$ 即为最后一个节点的状态\n",
    "$$ P^* = \\max_j \\delta_T(j) $$\n",
    "$$ s_T^* = \\argmax_j \\delta_T(j) $$\n",
    "\n",
    "4. 往前回溯\n",
    "$$ s_t^* = \\psi_{t+1}(s_{t+1}^*) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](HMM_greeks_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0. , 1. , 0. , 0. ],\n",
       "        [0.4, 0. , 0.6, 0. ],\n",
       "        [0. , 0.4, 0. , 0.6],\n",
       "        [0. , 0. , 0.5, 0.5]]), array([[0.5, 0.5],\n",
       "        [0.3, 0.7],\n",
       "        [0.6, 0.4],\n",
       "        [0.8, 0.2]]), array([0.25, 0.25, 0.25, 0.25]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Generating Process\n",
    "\n",
    "observation_set = ['红', '白']\n",
    "statet_set = ['box1', 'box2', 'box3', 'box4']\n",
    "\n",
    "M = len(observation_set)\n",
    "N = len(statet_set)\n",
    "\n",
    "# lambda = (pi, A, B)\n",
    "pi = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "A = np.array([[0, 1, 0, 0],\n",
    "              [.4, 0, .6, 0],\n",
    "              [0, .4, 0, .6],\n",
    "              [0, 0, .5, .5],\n",
    "             ])\n",
    "B = np.array([[.5, .5],\n",
    "              [.3, .7],\n",
    "              [.6, .4],\n",
    "              [.8, .2],\n",
    "             ])\n",
    "\n",
    "def generate_one_sample(pi, A, B, T=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
