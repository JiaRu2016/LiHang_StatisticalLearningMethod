{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT & XGBoost\n",
    "\n",
    "$$ \n",
    "CART\n",
    "\\xrightarrow[]{\\text{fit residual term, SSE loss}}\n",
    "BoostingTree \n",
    "\\xrightarrow[]{\\text{generalized loss-function} \\quad  L(\\cdot)}\n",
    "GBDT  \n",
    "\\xrightarrow[\\text{pruning, NA, parallel, etc.}]{ \\text{add regulation term} \\quad \\gamma T + \\frac{1}{2}\\|w\\|^2}\n",
    "XGBoost\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT\n",
    "\n",
    "$L(\\cdot)$不再具有平方误差的具体形式，而是一般化的损失函数。\n",
    "\n",
    "使用 <u>**损失函数的负梯度 在当前模型的值**</u> 作为残差的替代\n",
    "\n",
    "$$ r_{mi} = - \\frac{\\partial L(y_i, \\hat{y}_i)}{\\partial \\hat{y}_i} \\Big|_{ \\hat{y}_i = f_{m-1}(x_i) }   $$\n",
    "\n",
    "下一个基回归树对 $r_{mi}$ 进行拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入正则项\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_i L(y_i, \\hat{y}_i) + \\sum_k \\Omega(f_k)\n",
    "$$\n",
    "\n",
    "其中  $$ \\Omega(\\cdot) = \\gamma T + \\frac{\\lambda}{2} \\|w\\|^2 $$ 是单棵树复杂度的度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法模型 && 前向分步算法，第 $t$ 步的目标函数为\n",
    "\n",
    "$$ \\mathcal{L}^{(t)} = \\sum_i L\\big(y_i, \\quad \\hat{y}_i^{(t-1)} + f_t(x_i) \\big) + \\Omega(f_t) + Constant$$\n",
    "\n",
    "（注意优化的自变量为 $f_t$）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 $\\Omega(f_t)$ 展开，得到\n",
    "\n",
    "$$ \n",
    "\\mathcal{L}^{(t)} = \\sum_i L(y_i, \\hat{y}_i^{(t-1)} + f_t(x_i) ) + \\gamma T + \\frac{\\lambda}{2} \\sum_{j=1}^T w_j^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 $\\hat{y}_i^{(t-1)}$ 处展开 （同GBDT，在 **当前模型的值** 处展开），展开步长为 $f_t(x_i)$ \n",
    "\n",
    "> [这个回答](https://www.zhihu.com/question/63560633/answer/375811211)\n",
    "> \n",
    "> 二阶泰勒展开\n",
    "$$ f(x + \\Delta x) = f(x) + f^\\prime(x) \\Delta x + \\frac{1}{2} f^{\\prime\\prime} (x) \\Delta x^2$$\n",
    "这里 x 为当前模型输出值 $\\hat{y}_i^{(t-1)}$， 而 $\\Delta x$ 为本次新加入的树 $f_t(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展开后的目标函数\n",
    "\n",
    "$$ \n",
    "\\mathcal{L}^{(t)} = \\sum_i \\Big[ L(y_i, \\hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \\frac{1}{2} h_i f_t(x_i)^2 \\Big]  \n",
    "+ \\gamma T + \\frac{\\lambda}{2} \\sum_{j=1}^T w_j^2\n",
    "$$\n",
    "\n",
    "其中 $g_i, h_i$ 为 $L$ 的一阶导数、二阶导数 在 $(y_i, \\hat{y}_i^{(t-1)})$  处的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中括号中的第一项也是Constant，可以忽略；\n",
    "\n",
    "重新排列组合，按照叶子节点重新组合，注意 $f_t(x_i)$ 一定属于某个 $R_j$ 从而等于某个 $wj$\n",
    "\n",
    "$$ \\mathcal{L}^{(t)} = \\sum_{j=1}^T \\Big[ g_j w_j + \\frac{h_j + \\lambda}{2} w_j^2 \\Big] + \\gamma T$$\n",
    "\n",
    "$$\\text{where} \\quad g_j = \\sum_{x_i \\in R_j} g_i , \\quad h_j = \\sum_{x_i \\in R_j} h_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个关于 $w_j$ 的一元二次函数，根据顶点公式\n",
    "\n",
    "$$ w_j^* =  - \\frac{b}{2a} = - \\frac{g_j}{h_j + \\lambda} $$\n",
    "\n",
    "$$ Obj^* =  \\frac{4ac - b^2}{4a} = - \\frac{1}{2} \\sum_{j=1}^T \\frac{g_j^2}{(h_j + \\lambda)} + \\gamma T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> 上述逻辑解决的问题是“已知树的结构，如何确定w”，现在的问题是如何确定树结构 ？</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
